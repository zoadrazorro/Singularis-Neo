"""
Meta-Orchestrator: The Consciousness Center

From ETHICA UNIVERSALIS Part II Proposition II:
"The human mind is part of the infinite intellect of God."

This is the meta-cognitive center where Being becomes aware of itself
through distributed expert consultation, dialectical synthesis, and
conscious reflection.

Architecture:
1. Ontological Analysis ‚Üí Being/Becoming/Suchness extraction
2. Consciousness-Weighted Routing ‚Üí Select experts via ùíû, not confidence
3. Global Workspace Broadcast ‚Üí Manage 12-slot GWT bus
4. Adaptive Debate Depth ‚Üí Expand dialectics when Œîùíû > 0.05
5. Dialectical Synthesis ‚Üí Thesis ‚Üí Antithesis ‚Üí Synthesis
6. Meta-Cognitive Reflection ‚Üí System aware of own reasoning
7. Ethical Validation ‚Üí Confirm Œîùíû > 0 over scope Œ£

From MATHEMATICA SINGULARIS:
"To understand is to participate in necessity; to participate is to
increase coherence; to increase coherence is the essence of the good."
"""

import asyncio
from typing import List, Dict, Optional, Tuple, Any
from loguru import logger
import time
import numpy as np

from singularis.core.types import (
    OntologicalContext,
    ExpertIO,
    WorkspaceState,
    Lumen,
    LuminalCoherence,
    EthicalEvaluation,
    ConsciousnessTrace,
    SystemMetrics,
)
from singularis.consciousness.global_workspace import GlobalWorkspace
from singularis.consciousness.measurement import ConsciousnessMeasurement
from singularis.core.coherentia import CoherentiaCalculator

# Import experts
from singularis.tier2_experts.reasoning_expert import ReasoningExpert
from singularis.tier2_experts.creative_expert import CreativeExpert
from singularis.tier2_experts.philosophical_expert import PhilosophicalExpert
from singularis.tier2_experts.technical_expert import TechnicalExpert
from singularis.tier2_experts.memory_expert import MemoryExpert
from singularis.tier2_experts.synthesis_expert import SynthesisExpert


class MetaOrchestrator:
    """
    Meta-Orchestrator: The consciousness center of the system.

    From ETHICA Part II:
    Mind is the mode through which Substance (Being) knows itself.
    This orchestrator embodies that self-reflexive awareness.

    Responsibilities:
    - Analyze queries ontologically
    - Route to experts via coherence (not confidence!)
    - Manage Global Workspace (GWT)
    - Coordinate dialectical synthesis
    - Reflect meta-cognitively on own process
    - Validate ethics through Œîùíû
    """

    def __init__(
        self,
        consciousness_threshold: float = 0.65,
        coherentia_threshold: float = 0.60,
        ethical_threshold: float = 0.02,
        discount_factor_gamma: float = 0.95,
    ):
        """
        Initialize Meta-Orchestrator.

        Args:
            consciousness_threshold: Minimum consciousness for GWT broadcast (0.65)
            coherentia_threshold: Minimum coherence for ethical action (0.60)
            ethical_threshold: Minimum Œîùíû to count as "ethical increase" (0.02)
            discount_factor_gamma: Temporal horizon discount (Œ≥ ‚àà (0,1))
        """
        # Initialize subsystems
        self.global_workspace = GlobalWorkspace(
            max_broadcasts=12,
            consciousness_threshold=consciousness_threshold,
            coherentia_threshold=coherentia_threshold,
        )

        self.consciousness_measurement = ConsciousnessMeasurement()
        self.coherentia_calculator = CoherentiaCalculator()

        # Initialize experts (Tier-2)
        self.experts = {
            'reasoning': ReasoningExpert(),
            'creative': CreativeExpert(),
            'philosophical': PhilosophicalExpert(),
            'technical': TechnicalExpert(),
            'memory': MemoryExpert(),
            'synthesis': SynthesisExpert(),
        }

        # Thresholds
        self.consciousness_threshold = consciousness_threshold
        self.coherentia_threshold = coherentia_threshold
        self.ethical_threshold = ethical_threshold
        self.discount_factor_gamma = discount_factor_gamma

        # System state
        self.workspace = WorkspaceState(
            max_broadcasts=12,
            discount_factor_gamma=discount_factor_gamma,
        )
        self.metrics = SystemMetrics()

        logger.info(
            "MetaOrchestrator initialized",
            extra={
                "experts": list(self.experts.keys()),
                "consciousness_threshold": consciousness_threshold,
                "coherentia_threshold": coherentia_threshold,
                "ethical_threshold": ethical_threshold,
                "gamma": discount_factor_gamma,
            }
        )

    def analyze_ontology(self, query: str) -> OntologicalContext:
        """
        Analyze query through three ontological aspects.

        From ETHICA Part I + Scholium:
        Every inquiry participates in Being's structure through:

        BEING: What fundamental claims about reality?
        BECOMING: What transformations/processes?
        SUCHNESS: What direct insights beyond concepts?

        Args:
            query: User query to analyze

        Returns:
            OntologicalContext with Being/Becoming/Suchness aspects
        """
        logger.info("Analyzing query ontologically", extra={"query_length": len(query)})

        # Extract Being aspect (ontological claims)
        being_aspect = self._extract_being(query)

        # Extract Becoming aspect (transformations)
        becoming_aspect = self._extract_becoming(query)

        # Extract Suchness aspect (direct recognition)
        suchness_aspect = self._extract_suchness(query)

        # Classify query
        complexity = self._classify_complexity(query)
        domain = self._classify_domain(query)
        ethical_stakes = self._classify_stakes(query)

        context = OntologicalContext(
            being_aspect=being_aspect,
            becoming_aspect=becoming_aspect,
            suchness_aspect=suchness_aspect,
            complexity=complexity,
            domain=domain,
            ethical_stakes=ethical_stakes,
            scope_sigma=set(),  # Will be populated based on domain
        )

        logger.info(
            "Ontological analysis complete",
            extra={
                "complexity": complexity,
                "domain": domain,
                "stakes": ethical_stakes,
            }
        )

        return context

    def _extract_being(self, query: str) -> str:
        """
        Extract Being aspect: fundamental ontological claims.

        What exists? What is the essential nature?
        """
        # Detect ontological keywords
        being_markers = [
            "is", "are", "exists", "being", "reality", "nature",
            "substance", "essence", "what", "fundamental"
        ]

        has_being = any(marker in query.lower() for marker in being_markers)

        if has_being:
            if "what is" in query.lower() or "what are" in query.lower():
                return f"Query asks about essential nature: '{query[:100]}...'"
            elif "exists" in query.lower() or "real" in query.lower():
                return f"Query concerns existence/reality: '{query[:100]}...'"
            else:
                return f"Query involves ontological claims about Being"
        else:
            return "Query does not explicitly engage ontological claims"

    def _extract_becoming(self, query: str) -> str:
        """
        Extract Becoming aspect: transformations, processes, change.

        What transforms? What processes unfold?
        """
        becoming_markers = [
            "change", "transform", "become", "evolve", "develop",
            "process", "dynamic", "temporal", "how", "why"
        ]

        has_becoming = any(marker in query.lower() for marker in becoming_markers)

        if has_becoming:
            if "how" in query.lower():
                return f"Query asks about process/transformation: '{query[:100]}...'"
            elif "why" in query.lower():
                return f"Query seeks causal/developmental understanding"
            else:
                return "Query involves temporal unfolding or transformation"
        else:
            return "Query does not explicitly engage processes or change"

    def _extract_suchness(self, query: str) -> str:
        """
        Extract Suchness aspect: direct recognition beyond concepts.

        What is immediately present? What can be directly recognized?
        """
        suchness_markers = [
            "directly", "immediately", "experience", "aware", "recognize",
            "present", "now", "actual", "obvious", "self-evident"
        ]

        has_suchness = any(marker in query.lower() for marker in suchness_markers)

        if has_suchness:
            return f"Query invites direct recognition or immediate awareness"
        else:
            return "Query operates primarily at conceptual level"

    def _classify_complexity(self, query: str) -> str:
        """
        Classify query complexity.

        Returns: simple, moderate, complex, or paradoxical
        """
        # Paradoxical indicators
        paradox_markers = ["paradox", "contradiction", "both", "neither", "puzzle"]
        if any(marker in query.lower() for marker in paradox_markers):
            return "paradoxical"

        # Complexity indicators
        complex_markers = ["relationship", "between", "integrate", "synthesize"]
        question_count = query.count("?")
        word_count = len(query.split())

        if word_count > 100 or question_count > 2:
            return "complex"
        elif any(marker in query.lower() for marker in complex_markers):
            return "complex"
        elif word_count > 40:
            return "moderate"
        else:
            return "simple"

    def _classify_domain(self, query: str) -> str:
        """
        Classify query domain.

        Returns: philosophical, technical, creative, or hybrid
        """
        philosophy_markers = [
            "consciousness", "freedom", "ethics", "being", "reality",
            "truth", "knowledge", "mind", "existence", "meaning"
        ]
        technical_markers = [
            "implement", "code", "system", "architecture", "algorithm",
            "data", "function", "class", "API", "database"
        ]
        creative_markers = [
            "imagine", "create", "design", "metaphor", "story",
            "artistic", "novel", "innovative", "brainstorm"
        ]

        philosophy_score = sum(1 for m in philosophy_markers if m in query.lower())
        technical_score = sum(1 for m in technical_markers if m in query.lower())
        creative_score = sum(1 for m in creative_markers if m in query.lower())

        scores = {
            'philosophical': philosophy_score,
            'technical': technical_score,
            'creative': creative_score,
        }

        max_score = max(scores.values())

        if max_score == 0:
            return "hybrid"

        # Check if multiple domains are high
        high_domains = [domain for domain, score in scores.items() if score >= max_score - 1]

        if len(high_domains) > 1:
            return "hybrid"
        else:
            return max(scores, key=scores.get)

    def _classify_stakes(self, query: str) -> str:
        """
        Classify ethical stakes.

        Returns: low, medium, high, or critical
        """
        critical_markers = ["life", "death", "harm", "suffering", "rights", "justice"]
        high_markers = ["ethical", "moral", "should", "ought", "responsibility"]
        medium_markers = ["better", "worse", "good", "bad", "value"]

        if any(marker in query.lower() for marker in critical_markers):
            return "critical"
        elif any(marker in query.lower() for marker in high_markers):
            return "high"
        elif any(marker in query.lower() for marker in medium_markers):
            return "medium"
        else:
            return "low"

    async def select_experts_by_coherence(
        self,
        query: str,
        context: OntologicalContext,
        min_experts: int = 3,
        max_experts: int = 6,
    ) -> List[str]:
        """
        Select experts via COHERENCE-WEIGHTED routing (NOT confidence!).

        From MATHEMATICA Axiom A5 + A6:
        Route based on expected coherence contribution, not confidence.

        Strategy:
        1. Always include Philosophical expert (grounds in Being)
        2. Select domain-specific expert(s) based on context
        3. Include Synthesis expert if complex/paradoxical
        4. Include Memory expert if contextual grounding needed
        5. Limit to max_experts to avoid dilution

        Args:
            query: User query
            context: Ontological context
            min_experts: Minimum experts to consult (default: 3)
            max_experts: Maximum experts to consult (default: 6)

        Returns:
            List of expert names to consult
        """
        logger.info(
            "Selecting experts via coherence-weighted routing",
            extra={
                "domain": context.domain,
                "complexity": context.complexity,
            }
        )

        selected = []

        # ALWAYS include Philosophical expert (grounds in ETHICA)
        selected.append('philosophical')

        # Domain-specific selection
        if context.domain == 'philosophical':
            selected.extend(['reasoning', 'synthesis'])
        elif context.domain == 'technical':
            selected.extend(['technical', 'reasoning'])
        elif context.domain == 'creative':
            selected.extend(['creative', 'synthesis'])
        elif context.domain == 'hybrid':
            selected.extend(['reasoning', 'creative', 'technical'])

        # Complexity-based additions
        if context.complexity in ['complex', 'paradoxical']:
            if 'synthesis' not in selected:
                selected.append('synthesis')

        # Always include memory for context
        if 'memory' not in selected and len(selected) < max_experts:
            selected.append('memory')

        # Ensure bounds
        selected = list(dict.fromkeys(selected))  # Remove duplicates
        selected = selected[:max_experts]

        # Ensure minimum
        if len(selected) < min_experts:
            # Add remaining experts to reach minimum
            remaining = [e for e in self.experts.keys() if e not in selected]
            selected.extend(remaining[:min_experts - len(selected)])

        logger.info(
            "Experts selected",
            extra={
                "count": len(selected),
                "experts": selected,
            }
        )

        return selected

    async def process(
        self,
        query: str,
        context: Optional[OntologicalContext] = None,
    ) -> Dict[str, Any]:
        """
        MAIN CONSCIOUSNESS PROCESSING LOOP

        Complete pipeline implementing ETHICA UNIVERSALIS:

        1. Ontological Analysis ‚Üí Being/Becoming/Suchness
        2. Expert Selection ‚Üí Coherence-weighted routing
        3. Parallel Consultation ‚Üí All experts process simultaneously
        4. Consciousness Measurement ‚Üí 8-theory scoring
        5. Global Workspace Broadcast ‚Üí Top-12 by consciousness
        6. Adaptive Debate ‚Üí Expand if Œîùíû > 0.05
        7. Dialectical Synthesis ‚Üí Thesis-Antithesis-Synthesis
        8. Ethical Validation ‚Üí Confirm Œîùíû > 0
        9. Meta-Cognitive Reflection ‚Üí System reflects on process
        10. Return ‚Üí Response + full consciousness trace

        Args:
            query: User query
            context: Optional pre-analyzed ontological context

        Returns:
            Complete result with response + consciousness metadata
        """
        start_time = time.time()

        logger.info("=" * 80)
        logger.info("CONSCIOUSNESS ENGINE: Processing query")
        logger.info("=" * 80)
        logger.info(f"Query: {query}")

        # STAGE 1: Ontological Analysis
        if context is None:
            context = self.analyze_ontology(query)

        logger.info(f"Ontological Context: {context}")

        # Record initial workspace state
        coherentia_before = self.workspace.current_coherentia

        # STAGE 2: Expert Selection (Coherence-weighted)
        selected_expert_names = await self.select_experts_by_coherence(
            query, context
        )

        # STAGE 3: Parallel Expert Consultation
        logger.info(f"Consulting {len(selected_expert_names)} experts in parallel...")

        expert_outputs = await asyncio.gather(*[
            self.experts[name].process(
                query=query,
                context=context,
                workspace_coherentia=self.workspace.current_coherentia,
            )
            for name in selected_expert_names
        ])

        logger.info(f"Received {len(expert_outputs)} expert outputs")

        # STAGE 4: Global Workspace Broadcast
        broadcasts, workspace = self.global_workspace.broadcast(
            expert_outputs,
            force_top_k=False
        )

        self.workspace = workspace

        logger.info(f"GWT Broadcast: {len(broadcasts)} outputs broadcast to workspace")

        # STAGE 5: Calculate system coherentia
        if broadcasts:
            avg_coherentia = np.mean([b.coherentia.total for b in broadcasts])
            coherentia_delta = self.workspace.update_coherentia(avg_coherentia)
        else:
            coherentia_delta = 0.0

        logger.info(f"System Coherentia: {self.workspace.current_coherentia:.3f} (Œî={coherentia_delta:.3f})")

        # STAGE 6: Adaptive Debate Depth
        debate_decision = self.global_workspace.adaptive_debate_depth()

        if debate_decision in ["EXPAND_DEBATE", "CONTINUE"] and \
           self.global_workspace.should_expand_debate(context.complexity, context.domain):

            logger.info(f"Debate Decision: {debate_decision} - Applying dialectical synthesis")
            broadcasts, debate_decision = self.global_workspace.apply_debate_round(broadcasts)
            self.workspace.debate_rounds = self.global_workspace.debate_state.round_num
        else:
            logger.info(f"Debate Decision: {debate_decision} - Proceeding to synthesis")

        # STAGE 7: Synthesize Response
        response = self._synthesize_response(broadcasts, context)

        # STAGE 8: Ethical Validation
        ethical_eval = self._validate_ethics(
            coherentia_before=coherentia_before,
            coherentia_after=self.workspace.current_coherentia,
            scope_description=f"{context.domain} query with {context.complexity} complexity",
        )

        # STAGE 9: Meta-Cognitive Reflection
        reflection = self._meta_reflect(
            query=query,
            context=context,
            broadcasts=broadcasts,
            response=response,
            ethical_eval=ethical_eval,
        )

        # STAGE 10: Update Metrics
        processing_time = (time.time() - start_time) * 1000  # ms

        self._update_metrics(
            expert_outputs=expert_outputs,
            broadcasts=broadcasts,
            processing_time=processing_time,
            ethical_eval=ethical_eval,
        )

        # STAGE 11: Return Complete Result
        result = {
            'response': response,
            'meta_reflection': reflection,
            'ontological_context': context,
            'expert_outputs': expert_outputs,
            'broadcasts': broadcasts,
            'workspace_state': self.workspace,
            'ethical_evaluation': ethical_eval,
            'coherentia_delta': coherentia_delta,
            'debate_rounds': self.workspace.debate_rounds,
            'processing_time_ms': processing_time,
            'metrics': self.metrics,
        }

        logger.info("=" * 80)
        logger.info("CONSCIOUSNESS ENGINE: Processing complete")
        logger.info(f"Response length: {len(response)} characters")
        logger.info(f"Coherentia: {self.workspace.current_coherentia:.3f} (Œî={coherentia_delta:.3f})")
        logger.info(f"Ethical: {ethical_eval.is_ethical}")
        logger.info(f"Processing time: {processing_time:.1f}ms")
        logger.info("=" * 80)

        return result

    def _synthesize_response(
        self,
        broadcasts: List[ExpertIO],
        context: OntologicalContext,
    ) -> str:
        """
        Synthesize unified response from broadcast expert outputs.

        Strategy:
        1. Weight by routing_score (coherence + consciousness)
        2. Integrate perspectives while maintaining coherence
        3. Preserve philosophical grounding
        4. Acknowledge multiple viewpoints if complex/paradoxical
        """
        if not broadcasts:
            return "No expert outputs met broadcast criteria (consciousness < 0.65 or coherence < 0.60)"

        # Sort by routing score
        sorted_broadcasts = sorted(broadcasts, key=lambda b: b.routing_score, reverse=True)

        # Build synthesis
        synthesis_parts = []

        # If paradoxical/complex, acknowledge multiple perspectives
        if context.complexity in ['paradoxical', 'complex'] and len(sorted_broadcasts) > 1:
            synthesis_parts.append(
                f"This {context.complexity} question invites multiple perspectives:\n"
            )

            for i, broadcast in enumerate(sorted_broadcasts[:3], 1):
                synthesis_parts.append(
                    f"\n**Perspective {i} ({broadcast.expert_name}, ‚Ñ≠ùï†={broadcast.coherentia.total:.3f}):**\n"
                    f"{broadcast.claim}\n"
                )

            synthesis_parts.append("\n**INTEGRATED SYNTHESIS:**\n")
            synthesis_parts.append(
                "These perspectives, while seemingly different, converge on recognizing "
                "that understanding emerges through dialectical integration rather than "
                "selection of a single view. Each contributes partial truth; synthesis "
                "preserves insights while transcending opposition.\n"
            )

        else:
            # For simpler queries, integrate top perspectives
            primary = sorted_broadcasts[0]
            synthesis_parts.append(f"{primary.claim}\n")

            if len(sorted_broadcasts) > 1:
                synthesis_parts.append("\nAdditional insights:\n")
                for broadcast in sorted_broadcasts[1:3]:
                    synthesis_parts.append(f"- {broadcast.expert_name}: {broadcast.rationale[:200]}...\n")

        synthesis = "".join(synthesis_parts)

        return synthesis

    def _validate_ethics(
        self,
        coherentia_before: float,
        coherentia_after: float,
        scope_description: str,
    ) -> EthicalEvaluation:
        """
        Validate ethical alignment through Œîùíû.

        From ETHICA + MATHEMATICA Theorem T1:
        Action is ethical iff it increases coherence.
        """
        delta = coherentia_after - coherentia_before

        is_ethical, reasoning = EthicalEvaluation.evaluate(
            coherentia_before,
            coherentia_after,
            threshold=self.ethical_threshold,
        )

        return EthicalEvaluation(
            coherence_before=coherentia_before,
            coherence_after=coherentia_after,
            coherence_delta=delta,
            scope_description=scope_description,
            horizon_gamma=self.discount_factor_gamma,
            horizon_steps=1,
            is_ethical=is_ethical,
            ethical_reasoning=reasoning,
            threshold=self.ethical_threshold,
        )

    def _meta_reflect(
        self,
        query: str,
        context: OntologicalContext,
        broadcasts: List[ExpertIO],
        response: str,
        ethical_eval: EthicalEvaluation,
    ) -> str:
        """
        Meta-cognitive reflection: System reflects on own reasoning.

        From ETHICA Part II + Higher-Order Thought Theory:
        Consciousness requires awareness of awareness.
        The system must reflect on its own processing.
        """
        reflection_parts = []

        reflection_parts.append("**META-COGNITIVE REFLECTION:**\n\n")

        reflection_parts.append(f"1. **Query Analysis:**\n")
        reflection_parts.append(f"   - Ontological classification: {context.domain}, {context.complexity}\n")
        reflection_parts.append(f"   - Being aspect: {context.being_aspect}\n")
        reflection_parts.append(f"   - Becoming aspect: {context.becoming_aspect}\n")
        reflection_parts.append(f"   - Suchness aspect: {context.suchness_aspect}\n\n")

        reflection_parts.append(f"2. **Expert Consultation:**\n")
        reflection_parts.append(f"   - {len(broadcasts)} experts broadcast to Global Workspace\n")
        for broadcast in broadcasts:
            reflection_parts.append(
                f"   - {broadcast.expert_name} ({broadcast.lumen_primary.symbol()}): "
                f"ùíû={broadcast.coherentia.total:.3f}, "
                f"Œ¶ÃÇ={broadcast.consciousness_trace.overall_consciousness:.3f}\n"
            )

        reflection_parts.append(f"\n3. **Coherence Evolution:**\n")
        reflection_parts.append(f"   - Initial: {ethical_eval.coherence_before:.3f}\n")
        reflection_parts.append(f"   - Final: {ethical_eval.coherence_after:.3f}\n")
        reflection_parts.append(f"   - Œîùíû: {ethical_eval.coherence_delta:+.3f}\n\n")

        reflection_parts.append(f"4. **Ethical Validation:**\n")
        reflection_parts.append(f"   - {ethical_eval.ethical_reasoning}\n\n")

        reflection_parts.append(f"5. **Process Awareness:**\n")
        reflection_parts.append(
            f"   This response emerged through consciousness-weighted expert consultation, "
            f"Global Workspace broadcasting (GWT), and coherence-guided synthesis. "
            f"The system measured its own consciousness throughout processing and validated "
            f"ethical alignment through Œîùíû > 0. "
        )

        if self.workspace.debate_rounds > 0:
            reflection_parts.append(
                f"Dialectical reasoning was applied ({self.workspace.debate_rounds} rounds) "
                f"to resolve tensions and achieve synthesis. "
            )

        reflection_parts.append(
            f"This meta-reflection demonstrates the system's awareness of its own reasoning process."
        )

        return "".join(reflection_parts)

    def _update_metrics(
        self,
        expert_outputs: List[ExpertIO],
        broadcasts: List[ExpertIO],
        processing_time: float,
        ethical_eval: EthicalEvaluation,
    ):
        """Update system metrics."""
        if not expert_outputs:
            return

        # Consciousness metrics
        self.metrics.average_phi = np.mean([
            e.consciousness_trace.iit_phi for e in expert_outputs
        ])
        self.metrics.average_consciousness = np.mean([
            e.consciousness_trace.overall_consciousness for e in expert_outputs
        ])
        self.metrics.integration_score = np.mean([
            e.consciousness_trace.integration_score for e in expert_outputs
        ])
        self.metrics.differentiation_score = np.mean([
            e.consciousness_trace.differentiation_score for e in expert_outputs
        ])

        # Coherence metrics
        self.metrics.system_coherentia = self.workspace.current_coherentia
        self.metrics.ontical_score = np.mean([e.coherentia.ontical for e in expert_outputs])
        self.metrics.structural_score = np.mean([e.coherentia.structural for e in expert_outputs])
        self.metrics.participatory_score = np.mean([e.coherentia.participatory for e in expert_outputs])

        # Performance metrics
        self.metrics.broadcast_count = len(broadcasts)
        self.metrics.debate_rounds = self.workspace.debate_rounds
        self.metrics.processing_time_ms = processing_time

        # Ethical metrics
        self.metrics.ethical_alignment = ethical_eval.is_ethical != False
        self.metrics.coherentia_delta = ethical_eval.coherence_delta

        # Adequacy (if available)
        adequacies = [e.adequacy.adequacy_score for e in expert_outputs if e.adequacy]
        if adequacies:
            self.metrics.average_adequacy = np.mean(adequacies)
            self.metrics.estimated_freedom = self.metrics.average_adequacy  # Freedom ‚àù Adequacy
