<div align="center">

# üß† Singularis

### *Unified AGI Architecture for Life & Games*

**Twin AGI Systems: Life Operations + Skyrim Intelligence**

*Bridging philosophy, neuroscience, personal life tracking, and gaming AI through consciousness-driven architecture*

---

[![Version](https://img.shields.io/badge/version-Beta%20v3.5-blue.svg)](https://github.com/zoadrazorro/Singularis-Neo/releases)
[![Python](https://img.shields.io/badge/python-3.10%2B-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Status](https://img.shields.io/badge/status-Research%20Prototype-orange.svg)](https://github.com/zoadrazorro/Singularis-Neo)
[![Stars](https://img.shields.io/github/stars/zoadrazorro/Singularis-Neo?style=social)](https://github.com/zoadrazorro/Singularis-Neo/stargazers)
[![Issues](https://img.shields.io/github/issues/zoadrazorro/Singularis-Neo)](https://github.com/zoadrazorro/Singularis-Neo/issues)
[![Forks](https://img.shields.io/github/forks/zoadrazorro/Singularis-Neo?style=social)](https://github.com/zoadrazorro/Singularis-Neo/network/members)

**‚ö†Ô∏è Research Prototype** | **üìÖ Last Updated: November 16, 2025**

</div>

---

## What This Actually Does

Singularis is a modular AGI architecture with two specialized systems:

### 1. **Life Operations AGI** üè†
Personal life tracking and intelligence:
- Tracks life events (sleep, exercise, health, camera feeds, tasks, calendar)
- Analyzes patterns with AGI reasoning (GPT-5)
- Answers natural language queries ("How did I sleep last week?")
- Provides intelligent interventions based on context
- **Sophia Dashboard**: Web + mobile UI for life examination
- **Productivity Module**: Calendar/task sync with intelligent suggestions
- Integrates: Fitbit, home cameras, Messenger bot, Meta Glasses, Google Calendar, Todoist, Notion, Home Assistant

### 2. **Skyrim AGI** üéÆ
Autonomous game-playing intelligence:
- Takes screenshots and analyzes game state
- Decides actions using hybrid reasoning (fast heuristics + GPT-4.1 Nano)
- Controls game via virtual gamepad
- Learns from outcomes using temporal binding

**Current State**: Both systems work independently. Life Ops is production-ready for personal use. Skyrim AGI works in test scenarios.

## Core Features

### Life Operations (Production Ready) ‚úÖ

1. **Life Timeline**
   - SQLite database of all life events
   - Multiple sources: Fitbit, cameras, Messenger, manual
   - Query by time, type, source, user

2. **AGI-Powered Vision**
   - Gemini 2.5 Flash analyzes home camera feeds
   - Extracts structured events: person detected, motion, falls, activities
   - Confidence scores and context understanding

3. **Pattern Detection**
   - AGI Pattern Arbiter (GPT-5) finds correlations
   - Sleep quality, exercise habits, daily routines
   - Emergency detection with false-positive prevention

4. **Natural Language Queries**
   - Ask questions about your life data
   - "How did I sleep last week?" ‚Üí AGI-powered analysis
   - Integrates with Messenger bot for conversational interface

5. **Intelligent Interventions**
   - Context-aware notifications (time, mood, routine)
   - Empathy-driven decision making (Double Helix)
   - Wellness checks, reminders, insights

6. **Sophia Dashboard** ü¶â
   - Web + mobile visualization of life data
   - Interactive timeline, pattern cards, health metrics
   - AGI-powered conversational interface
   - "Ask Sophia" natural language queries
   - Philosophical insights and self-examination tools

7. **Productivity Integration**
   - Google Calendar, Todoist, Notion sync
   - Intelligent task suggestions based on context
   - Meeting preparation and follow-up automation
   - Time blocking and focus time recommendations

### Skyrim AGI (Research Prototype) üî¨

1. **Hybrid Action Selection**
   - Fast heuristics for simple decisions (~1ms)
   - GPT-4.1 Nano for complex decisions (~3-5s)
   - Automatically switches based on situation complexity

2. **Virtual Gamepad Control**
   - Sends Xbox 360 controller inputs to Skyrim
   - 20+ actions: movement, combat, camera control
   - Works with any game that accepts controller input

3. **Temporal Binding**
   - Links perception ‚Üí action ‚Üí outcome
   - Detects when agent is stuck in loops
   - Tracks success/failure of actions

4. **Conflict Prevention**
   - Prevents contradictory actions
   - Priority system (CRITICAL > HIGH > NORMAL > LOW)
   - Validates actions before execution

5. **Test Mode**
   - Run without game for testing
   - Mock AGI for development
   - Comprehensive test suite (56+ tests)

---

## Sephirot Cluster Architecture üå≥

Singularis is designed to run on a distributed cluster of nodes:

### Node Layout

**üß† Node A (AMD Tower)**: Cognitive Core
- Singularis consciousness layer
- API Gateway (FastAPI)
- Message bus (Redis)
- Orchestration services
- Dual AMD 7900 XT GPUs

**üß¨ Node B (Desktop)**: Memory & Observability
- Vector databases (ChromaDB)
- Life Timeline (PostgreSQL/SQLite)
- Monitoring stack (Prometheus + Grafana)
- Pattern analysis
- AMD 6900 XT GPU

**üïπÔ∏è Node C (Gaming Laptop)**: Skyrim Environment
- Skyrim AGI runtime
- Real-time control loop
- Telemetry agent
- NVIDIA RTX GPU

**üì± Node D (Lenovo Tab)**: Camera Monitor
- Roku Smart Home app (all camera feeds)
- ADB screen capture source
- Always-on display
- AGI vision processing via Node A

**üíª Node E (MacBook Pro)**: Dev Console
- Development environment
- Grafana dashboards
- SSH access to all nodes
- Operations control

**Edge Devices**:
- Phone: Messenger bot, Fitbit integration, life queries
- Meta Glasses: Vision + audio streaming (optional)

### Deployment

See `SEPHIROT_CLUSTER_ARCHITECTURE.md` and `DEPLOYMENT_CHECKLIST.md` for complete setup instructions.

---

## What's Experimental (Skyrim AGI)

- Vision system (Gemini/Qwen-VL) - works but rate-limited
- Learning/memory systems - implemented but not validated
- "Consciousness" metrics - philosophical concepts, not proven
- Voice/video systems - integrated but optional
- Many subsystems are templates or partially implemented

1. What the architecture is (Singularis Neo / SkyrimAGI)

Think of Singularis Neo as a distributed brain spread across several PCs, each with a specific cognitive role:

Core Pieces

ActionArbiter (on the gaming laptop) ‚Äì ‚ÄúPrefrontal cortex‚Äù

Receives candidate actions from different policies (exploration, combat, dialogue, safety, etc.).

Ranks them by confidence + priority (CRITICAL/HIGH/NORMAL/LOW).

Either:

picks an action locally (fast path), or

escalates to a larger LLM for deeper reasoning (slow path).

GPT Hybrid Coordinator ‚Äì ‚ÄúMeta-cognition‚Äù

Only used for 10‚Äì20% of decisions when things are confusing:

conflicting actions, low confidence, temporal weirdness, or periodic check-ins.

Takes full context (BeingState, recent history, candidate actions) and returns a single recommended action plus rationale.

Temporal Binding Engine ‚Äì ‚ÄúSense of continuity‚Äù

Links perception ‚Üí chosen action ‚Üí outcome into bindings.

Tracks which bindings close successfully vs. time out or loop.

Detects stuck patterns (e.g., pacing in circles, camera jitter).

Produces metrics like closure rate and temporal coherence that feed back into arbitration and learning.

BeingState ‚Äì ‚ÄúGlobal workspace / self-state‚Äù

Unified state object that holds:

game state, perception, memory recalls, health, goals, recent actions, etc.

Updated every cycle with fresh data from perception and memory nodes.

Is what both the local arbiter and LLM ‚Äúsee‚Äù when reasoning.

Conflict Prevention System ‚Äì ‚ÄúSafety & sanity checks‚Äù

Checks for:

stuck loops (‚â• N cycles)

low temporal coherence

subsystem disagreements

health/safety issues

Applies override rules based on priority (CRITICAL can override almost anything; LOW gets blocked easily).

Perception & Swarm Neurons (AMD tower)

Heavy vision models turn frames into structured scene descriptions and affordances.

Swarm of specialist LLMs (‚Äúneurons‚Äù) propose actions or evaluations:

navigation, combat, loot choice, dialogue style, risk assessment, etc.

RL / curriculum logic trains and refines these over time.

Memory Server (6900XT machine)

Vector database + embeddings.

Stores episodes, summaries, quest history, world facts, and long-term patterns.

Provides /memory/query and /memory/store style APIs so the core can recall or commit memories.

Control Plane NUC (MSI Cubi)

API gateway, message bus, and metrics stack.

Central place for:

routing requests between nodes

collecting telemetry (coherence, closure rate, conflicts, GPT usage)

managing configs/experiments (exploration rate, thresholds).

Dev/Ops Console (MacBook)

Where you develop, deploy, and watch dashboards.

No heavy compute‚Äîjust control and observability.

2. What the program actually does in Skyrim

On each cycle, for Skyrim, Singularis Neo basically does:

See the world

Captures the current frame + game state (health, enemies, position, UI).

Optionally ships the frame to the AMD tower for rich vision analysis.

Updates BeingState with perception and any recalled memories.

Propose what to do

Multiple policies (exploration, combat, dialogue, safety, etc.) each propose 1‚Äì3 candidate actions (with confidence scores).

Swarm neurons on the AMD box can also propose or critique actions.

Decide how to decide

ActionArbiter checks:

Are candidates high-confidence and non-conflicting?

Is temporal coherence good?

Are we not in a stuck loop?

If ‚Äúsimple case‚Äù: pick locally (fast path).

If ‚Äúhard case‚Äù: call the main LLM for deeper reasoning (slow path).

Validate and execute the action

Conflict system verifies:

not unsafe

not obviously looping

priority rules respected

If valid, the action is translated into virtual gamepad inputs and sent to Skyrim (move, attack, talk, loot, etc.).

Bind action to outcome

Temporal Binding Engine:

records the context + action as an open binding,

observes what happens next,

closes the binding when consequences are visible or times out.

Updates metrics: closure rate, loop counts, temporal coherence.

Learn and update memory

Memory server stores the new episode / insight.

RL and swarm components can be updated off-line (on the AMD tower) using recorded gameplay.

Coherence and binding metrics slowly shape which policies are trusted more.

Do it again

The loop repeats, typically with local decisions ~80‚Äì90% of the time and LLM escalations only when needed.

3. In one sentence

SkyrimAGI / Singularis Neo is a distributed AGI-style system that watches the game, remembers what worked, proposes multiple possible actions, arbitrates between them using both fast local logic and slower LLM reasoning, executes the chosen action through a virtual controller, and continuously tracks cause-and-effect over time so it can stay coherent, avoid getting stuck, and gradually improve its behavior as an autonomous Skyrim player.

---

## Quick Start

### Life Operations Demo

```bash
# 1. Install dependencies
cd integrations
pip install -r requirements.txt

# 2. Set up API keys
cp .env.example .env
# Edit .env with your API keys:
# - GEMINI_API_KEY (for AGI vision)
# - OPENAI_API_KEY (for GPT-5)
# - MESSENGER_PAGE_TOKEN (optional)

# 3. Run main orchestrator
python main_orchestrator.py

# 4. Test life query (in another terminal)
curl -X POST http://localhost:8080/query \
  -H "Content-Type: application/json" \
  -d '{"user_id":"test","query":"What patterns do you see?"}'
```

**What you'll see**:
- Main orchestrator starts
- Life Timeline initialized
- AGI consciousness connected
- API endpoints available at http://localhost:8080
- Query handler ready for natural language questions

### Skyrim AGI Demo (Test Mode - No Game Required)

```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. Set up API key (optional for test mode)
echo "OPENAI_API_KEY=your-key-here" > .env

# 3. Run test mode (60 seconds)
python run_beta_v3.py --test-mode --duration 60
```

**What you'll see**: 
- System initializes hybrid coordination
- Generates random action candidates
- Selects actions using fast local OR GPT-4.1 Nano
- Executes via virtual gamepad (no game needed)
- Prints statistics every 60 seconds

**Expected output**:
```
Actions: 15-20 successful
Fast local: 80-90%
GPT-4.1: 10-20%
Temporal coherence: ~1.0
```

## Full Setup (With Skyrim)

**Requirements**:
- Skyrim running in windowed mode
- OpenAI API key for GPT-4.1 Nano
- Google API key for Gemini vision (optional)
- ~2GB RAM for local vision models

**Warning**: This is experimental. Expect issues with:
- API rate limits (Gemini: 30 RPM free tier)
- Vision model accuracy
- Action execution timing
- Stuck loops in complex scenarios

```bash
# Run with full SkyrimAGI
python run_beta_v3.py

# Monitor in real-time
# Watch console for action decisions and stats
```

**For detailed setup**: See `docs/SETUP.md` (if it exists)

---

## Architecture Overview

### Life Operations Architecture

```
Data Sources (Fitbit, Cameras, Messenger)
    ‚Üì
Life Timeline (SQLite/PostgreSQL)
    ‚Üì
Pattern Engine (AGI Pattern Arbiter)
    ‚Üì
Unified Consciousness Layer (GPT-5)
    ‚Üì
Life Query Handler
    ‚Üì
Outputs (Messenger bot, API, Interventions)
```

**Key Components**:
- `life_timeline.py`: Event database
- `pattern_engine.py`: Pattern detection
- `life_query_handler.py`: Natural language queries
- `agi_pattern_arbiter.py`: GPT-5 powered analysis
- `main_orchestrator.py`: Coordinates all integrations

### Skyrim AGI Architecture

**High-level flow**: Perception ‚Üí State Update ‚Üí Action Selection (Fast/GPT) ‚Üí Conflict Check ‚Üí Execute ‚Üí Learn

**For detailed architecture**: See `SKYRIM_AGI_ARCHITECTURE.md`

### Simplified Flow

```
Game Screenshot
      ‚Üì
Vision System (Gemini/Qwen)
      ‚Üì
State Update (BeingState)
      ‚Üì
Generate 2-3 Action Candidates
      ‚Üì
Decision: Simple or Complex?
      ‚îú‚îÄ Simple ‚Üí ‚ö° Fast Local (<1ms) - Pick highest confidence
      ‚îî‚îÄ Complex ‚Üí üß† GPT-4.1 Nano (3-5s) - Reason about options
      ‚Üì
Conflict Check (stuck loops, health, etc.)
      ‚Üì
Execute via Virtual Gamepad
      ‚Üì
Observe Outcome & Learn
```

**Key insight**: Most decisions are simple (80-90%) so we use fast heuristics. Only complex/ambiguous situations need GPT-4.1.

---

## Key Components

### Life Operations Modules

**Core**:
- `integrations/life_timeline.py` - Event database and queries
- `integrations/pattern_engine.py` - Pattern detection engine
- `integrations/main_orchestrator.py` - Main coordinator
- `singularis/life_ops/life_query_handler.py` - Natural language queries
- `singularis/life_ops/agi_pattern_arbiter.py` - GPT-5 pattern analysis
- `singularis/life_ops/agi_intervention_decider.py` - Intelligent interventions

**Integrations**:
- `integrations/messenger_bot_adapter.py` - Facebook Messenger bot
- `integrations/fitbit_health_adapter.py` - Fitbit data sync
- `integrations/roku_screencap_gateway.py` - Camera feed processing
- `integrations/meta_glasses_adapter.py` - Meta Glasses integration
- `integrations/Sophia/` - Web dashboard + mobile app
- `integrations/Sophia/productivity/` - Calendar/task management

### Skyrim AGI Modules

**Core**:
- `run_beta_v3.py` - Main entry point, test/production modes
- `singularis/skyrim/action_arbiter.py` - Action selection & validation
- `singularis/core/being_state.py` - Unified state management
- `singularis/core/temporal_binding.py` - Perception-action-outcome tracking
- `singularis/skyrim/actions.py` - Virtual gamepad control
- `singularis/llm/gpt5_orchestrator.py` - GPT-4.1 Nano integration

### Priority System

- **CRITICAL**: Survival (health < 20), overrides everything
- **HIGH**: Combat, urgent actions
- **NORMAL**: Exploration, standard gameplay
- **LOW**: Idle, background tasks

---

## Configuration

### BetaV3Config

```python
@dataclass
class BetaV3Config:
    # General
    test_mode: bool = False  # False = Production with full SkyrimAGI
    duration_seconds: Optional[int] = None
    verbose: bool = False
    
    # GPT-4.1 Nano Coordination (Hybrid System)
    enable_gpt5: bool = True  # Enable hybrid coordination
    gpt5_model: str = "gpt-4.1-nano-2025-04-14"  # GPT-4.1 Nano
    openai_api_key: Optional[str] = None  # Load from .env
    
    # Action Arbiter
    enable_conflict_prevention: bool = True
    enable_temporal_tracking: bool = True
    
    # Temporal Binding
    temporal_window_size: int = 20
    temporal_timeout: float = 30.0
    target_closure_rate: float = 0.95
    
    # Monitoring
    stats_interval: int = 60  # Print stats every 60s
    checkpoint_interval: int = 300  # Save checkpoint every 5min
```

---

## Testing

### Test Suite

**Total**: 56+ tests across 4 test files

1. **Core Tests** (`test_beta_v3_core.py`)
   - BeingState: 7 tests
   - TemporalBinding: 6 tests

2. **Arbiter Tests** (`test_beta_v3_arbiter.py`)
   - Basic functionality: 4 tests
   - Conflict prevention: 4 tests
   - Temporal closure: 3 tests
   - GPT-5 coordination: 2 tests

3. **Phase 3 Integration** (`test_phase3_integration.py`)
   - Full integration: 11 tests

4. **Original Phase 2** (`test_action_arbiter.py`)
   - ActionArbiter: 10 tests

### Run Tests

```bash
# All tests
python run_beta_v3_tests.py

# Quick tests only
python run_beta_v3_tests.py --quick

# With coverage
python run_beta_v3_tests.py --coverage

# Specific category
pytest tests/ -m core -v
pytest tests/ -m arbiter -v
pytest tests/ -m phase3 -v
```

---

## Performance (Test Mode Observations)

**Note**: These are from controlled test scenarios, not real gameplay.

### Decision Speed

| Method | Time | Usage |
|--------|------|-------|
| Fast Local | <1ms | 80-90% of decisions |
| GPT-4.1 Nano | 2-5s | 10-20% of decisions |
| Average | ~0.5s | Depends on complexity |

### Test Mode Results (60s run)

- **Actions executed**: 15-20
- **Success rate**: High (test mode has no failure conditions)
- **Temporal coherence**: 1.0 (test mode is deterministic)
- **Stuck loops**: 0 (test mode doesn't get stuck)

### Real Gameplay (Anecdotal)

- **Vision accuracy**: Variable, depends on scene complexity
- **Action appropriateness**: Mixed, needs tuning
- **Stuck loop recovery**: Works sometimes
- **API rate limits**: Frequent issue with free tier Gemini

**Bottom line**: Works in test mode. Real gameplay needs more work.

---

## Usage Examples

### Basic Usage

```python
from singularis.core.being_state import BeingState
from singularis.core.temporal_binding import TemporalCoherenceTracker
from singularis.skyrim.action_arbiter import ActionArbiter, ActionPriority

# Initialize systems
being_state = BeingState()
temporal_tracker = TemporalCoherenceTracker()
arbiter = ActionArbiter(skyrim_agi)

# Update subsystems
being_state.update_subsystem('sensorimotor', {
    'status': 'MOVING',
    'analysis': 'Forward movement detected'
})

# Request action
result = await arbiter.request_action(
    action='move_forward',
    priority=ActionPriority.NORMAL,
    source='reasoning',
    context={
        'perception_timestamp': time.time(),
        'scene_type': 'exploration',
        'game_state': game_state
    }
)
```

### With GPT-5 Coordination

```python
from singularis.llm.gpt5_orchestrator import GPT5Orchestrator

# Initialize GPT-5
gpt5 = GPT5Orchestrator(api_key=os.getenv("OPENAI_API_KEY"))
gpt5.register_system("action_arbiter", SystemType.ACTION)

# Create arbiter with GPT-5
arbiter = ActionArbiter(
    skyrim_agi=agi,
    gpt5_orchestrator=gpt5,
    enable_gpt5_coordination=True
)

# Coordinate action decision
candidate_actions = [
    {'action': 'explore', 'priority': 'NORMAL', 'source': 'reasoning', 'confidence': 0.8},
    {'action': 'wait', 'priority': 'LOW', 'source': 'idle', 'confidence': 0.3}
]

selected = await arbiter.coordinate_action_decision(
    being_state=being_state,
    candidate_actions=candidate_actions
)
```

### Conflict Prevention

```python
# Check for conflicts
is_allowed, reason = arbiter.prevent_conflicting_action(
    action='move_forward',
    being_state=being_state,
    priority=ActionPriority.NORMAL
)

if not is_allowed:
    print(f"Action blocked: {reason}")
```

### Temporal Binding Closure

```python
# Check closure rate
closure_result = arbiter.ensure_temporal_binding_closure(
    being_state=being_state,
    temporal_tracker=temporal_tracker
)

print(f"Closure rate: {closure_result['closure_rate']:.1%}")
print(f"Status: {closure_result['status']}")

if not closure_result['meets_target']:
    for rec in closure_result['recommendations']:
        print(f"  - {rec}")
```

---

## Documentation

### Life Operations
- **Phase 1-5 Complete**: `integrations/PHASE_*_COMPLETE.md`
- **Cluster Architecture**: `SEPHIROT_CLUSTER_ARCHITECTURE.md`
- **Deployment Guide**: `DEPLOYMENT_CHECKLIST.md`
- **Modular Architecture**: `MODULAR_ARCHITECTURE.md`
- **Usage Guide**: `MODULAR_USAGE_GUIDE.md`

### Skyrim AGI
- **Testing Guide**: `BETA_V3_TESTING_GUIDE.md`
- **Phase 3 Complete**: `PHASE_3_COMPLETE.md`
- **Quick Reference**: `PHASE_3_QUICK_REFERENCE.md`
- **Implementation Summary**: `PHASE_3_IMPLEMENTATION_SUMMARY.md`

---

## What's Actually Complete

### Life Operations (November 16, 2025) ‚úÖ

**Production Ready**:
- ‚úÖ Life Timeline database (SQLite/PostgreSQL)
- ‚úÖ AGI-powered camera vision (Gemini 2.5 Flash)
- ‚úÖ Pattern detection with GPT-5
- ‚úÖ Natural language queries
- ‚úÖ Messenger bot integration
- ‚úÖ Fitbit health data sync
- ‚úÖ Intelligent interventions
- ‚úÖ REST API (`/query`, `/timeline`, `/health`, `/chat`)
- ‚úÖ Sophia Dashboard (FastAPI backend + React Native mobile)
- ‚úÖ Productivity sync service (Google Calendar, Todoist, Notion)
- ‚úÖ Home Assistant integration
- ‚úÖ Modular architecture (6 independent modules)
- ‚úÖ Sephirot cluster deployment plan

**Phases Complete**:
1. ‚úÖ Life Timeline ‚Üî Consciousness bridge
2. ‚úÖ AGI-powered pattern detection
3. ‚úÖ Intelligent interventions with empathy
4. ‚úÖ AGI vision for camera feeds
5. ‚úÖ Natural language query interface
6. ‚úÖ Sophia dashboard (web + mobile)
7. ‚úÖ Productivity integration (calendar/tasks)

### Skyrim AGI - Beta v3.5 (November 14, 2025) üî¨

**Working**:
- ‚úÖ Hybrid action selection (fast local + GPT-4.1 Nano)
- ‚úÖ Virtual gamepad control (20+ actions)
- ‚úÖ Test mode with mock AGI
- ‚úÖ Temporal binding (perception-action-outcome tracking)
- ‚úÖ Conflict prevention (stuck loops, priorities)
- ‚úÖ Test suite (56+ tests passing)

**Partially Working**:
- ‚ö†Ô∏è Vision system (works but rate-limited, accuracy varies)
- ‚ö†Ô∏è Full SkyrimAGI integration (many subsystems are templates)
- ‚ö†Ô∏è Learning/memory (implemented but not validated)
- ‚ö†Ô∏è Real gameplay (works in simple scenarios, needs tuning)

**Experimental/Unproven**:
- üî¨ "Consciousness" metrics (philosophical concepts)
- üî¨ Voice/video systems (integrated but optional)
- üî¨ Long-term stability (not tested beyond short runs)
- üî¨ Complex gameplay scenarios

**Known Issues**:
- API rate limits (Gemini free tier: 30 RPM)
- Vision model accuracy in complex scenes
- Stuck loop recovery not always effective
- Many subsystems are placeholders

---

## What Needs Work

### High Priority
- [ ] Improve vision accuracy in complex scenes
- [ ] Reduce API rate limit issues
- [ ] Validate learning/memory systems
- [ ] Test real gameplay beyond simple scenarios
- [ ] Document actual performance in real gameplay

### Medium Priority
- [ ] Optimize action selection heuristics
- [ ] Add more robust stuck loop recovery
- [ ] Improve conflict prevention accuracy
- [ ] Add gameplay metrics dashboard

### Low Priority
- [ ] Validate "consciousness" metrics
- [ ] Test long-term stability (24+ hours)
- [ ] Optimize subsystem integration
- [ ] Add more action types

---

## Contributing

This is a research prototype. Contributions welcome, but understand:
- Many features are experimental
- No guarantees of stability
- API keys required for full functionality
- Setup can be complex

**To contribute**:
1. Try the test mode demo first
2. Read existing code and tests
3. Open an issue before major changes
4. Add tests for new features
5. Be realistic about what works

---

## License

See LICENSE file for details.

---

---

## Project Status

**Life Operations**: ‚úÖ Production Ready (personal use)  
**Skyrim AGI**: üî¨ Research Prototype  
**Architecture**: Modular, deployable on Sephirot cluster  
**Last Updated**: November 16, 2025  

**What Works**:
- Life tracking, pattern detection, natural language queries
- AGI-powered camera vision
- Messenger bot integration
- Modular architecture for independent deployment

**What's Experimental**:
- Skyrim AGI (works in test mode, needs real gameplay validation)
- Long-term stability (not tested beyond short runs)
- Full cluster deployment (documented but not deployed)

---

**Version**: 1.0.0 (Life Ops) / Beta v3.5 (Skyrim AGI)  
**License**: MIT  
**Repository**: [github.com/yourusername/Singularis](https://github.com/yourusername/Singularis)
